---
title: "Model Testing"
output: html_notebook
---
Here is cleaned up code to run our best model. Please edit the code in line 49 to load the secret data.

# load library
```{r}

library(tidyverse)
library(leaps) # contanis regsubset()
library(fastDummies) # to make dummy variables
library(corrplot) # for visualization but probably not needed in final.
library(boot) # load library boot to use cv.glm
library(glmnet) # for ridge regression and lasso regression
library(caret) # very helpful for training a model
library(earth)
library(gbm)
library(xgboost)

#library(doParallel)
#cl <- makePSOCKcluster(3)
#registerDoParallel(cl)
```
# model with split and preprocess together
```{r}
model_data <- readRDS("./model_data.rds")
model_xgb <- readRDS("./xgbModel.rds")

set.seed(1)
trainData.caret <- sample(1:nrow(model_data), 0.7*nrow(model_data))
data.caret.train <- model_data[trainData.caret,]
data.caret.test <- model_data[-trainData.caret,]
preProcess_model <- preProcess(data.caret.train, method=c("scale", "center", "bagImpute", "nzv"))
testData <- predict(preProcess_model, newdata = data.caret.test)
testData$int_rate <- data.caret.test$int_rate
```


# Predict Y on test set and calculate MSE
```{r}
predicted_xgb <- predict(model_xgb, testData)
(MSE_test <- mean((data.caret.test$int_rate-predicted_xgb)^2)) 
```

# load secret test data
```{r}

raw_data <- read.csv2("./LCdata.csv", header = TRUE, row.names=NULL, sep=";")

my_data <- raw_data

# drop columns per Gwen
my_data <- select(my_data, -c("collection_recovery_fee", "installment", "issue_d", "last_pymnt_amnt", "last_pymnt_d", "loan_status", "next_pymnt_d", "out_prncp", "out_prncp_inv", "pymnt_plan", "recoveries", "term", "total_pymnt", "total_pymnt_inv", "total_rec_int", "total_rec_late_fee", "total_rec_prncp")) 

# drop columns that are not useful

my_data <- select(my_data, -c("id", "member_id", "emp_title", "url", "desc", "title", "zip_code", "addr_state", "earliest_cr_line", "last_credit_pull_d", "policy_code"))

# my_data <- subset(my_data, select = -funded_amnt) I think this is more important than initially believed, but when I checked the data I found it did not make a difference. Leaving in anyway.

# convert character to floats
my_data$int_rate <- as.double(my_data$int_rate)
my_data$dti <- as.double(my_data$dti)
my_data$dti_joint <- as.double(my_data$dti_joint)
my_data$il_util <- as.double(my_data$il_util)
my_data$all_util <- as.double(my_data$all_util)
my_data$revol_util <- as.double(my_data$revol_util)

# convert character to integer
my_data$annual_inc <- as.integer(my_data$annual_inc)
my_data$annual_inc_joint <- as.integer(my_data$annual_inc_joint)
my_data$funded_amnt_inv <- as.integer(my_data$funded_amnt_inv)

# convert character to ordered integers
# Note: should this be categorical? or group them?
my_data$emp_length <- as.integer(ordered(my_data$emp_length, levels = c("n/a", "< 1 year", "1 year", "2 years", "3 years", "4 years", "5 years", "6 years", "7 years", "8 years", "9 years", "10+ years"))) - 1 # does this need to consider na as unemployed?

# drop NA
my_data <- filter(my_data, ! is.na(my_data$home_ownership))
my_data <- filter(my_data, ! is.na(my_data$annual_inc))
my_data <- filter(my_data, ! is.na(my_data$delinq_2yrs))
my_data <- filter(my_data, ! is.na(my_data$revol_bal))
my_data <- filter(my_data, ! is.na(my_data$revol_util))
my_data <- filter(my_data, ! is.na(my_data$collections_12_mths_ex_med))

# fix verification_status and verification_status_joint
my_data$verification_status <- ifelse(my_data$verification_status == "Source Verified", "Source", my_data$verification_status)
my_data$verification_status <- ifelse(my_data$verification_status == "Not Verified", "Not", my_data$verification_status)
my_data$verification_status_joint <- ifelse(my_data$verification_status == "Source Verified", "Source", my_data$verification_status)
my_data$verification_status_joint <- ifelse(my_data$verification_status == "Not Verified", "Not", my_data$verification_status)

#dummy columns
my_data <- dummy_columns(my_data, select_columns = "home_ownership", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
my_data <- dummy_columns(my_data, select_columns = "verification_status", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
my_data <- dummy_columns(my_data, select_columns = "purpose", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
my_data <- dummy_columns(my_data, select_columns = "application_type", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
my_data <- dummy_columns(my_data, select_columns = "verification_status_joint", remove_first_dummy = TRUE, remove_selected_columns = TRUE)
my_data <- dummy_columns(my_data, select_columns = "initial_list_status", remove_first_dummy = TRUE, remove_selected_columns = TRUE)

# Correct data errors
my_data$inq_last_12m <- ifelse(my_data$inq_last_12m < 0, my_data$inq_last_12m * -1, my_data$inq_last_12m) # eliminate negatives

# deal with joint income and joint dti
debt_payment.ind <- my_data$dti * my_data$annual_inc
debt_payment.joint <- my_data$dti_joint * my_data$annual_inc_joint
debt_payment.applicant <- ifelse(my_data$application_type_JOINT == 1, debt_payment.ind + debt_payment.joint, debt_payment.ind)

annual_inc.applicant <- ifelse(my_data$application_type_JOINT == 1, my_data$annual_inc + my_data$annual_inc_joint, my_data$annual_inc)

dti.applicant <- debt_payment.applicant / annual_inc.applicant

my_data$annual_inc <- annual_inc.applicant

my_data$dti <- ifelse(is.na(dti.applicant), my_data$dti, dti.applicant)

# drop joint data now that is not used
my_data <- select(my_data, -c("annual_inc_joint", "dti_joint"))

# remove outliers
my_data$annual_inc <- ifelse(my_data$annual_inc >= 1000000, my_data$annual_inc / 100, my_data$annual_inc)

secret_data <- my_data #make test modeling data
testData <- predict(preProcess_model, newdata = secret_data)
testData$int_rate <- secret_data$int_rate
```

# Predict Y on test set and calculate MSE
```{r}
predicted_xgb <- predict(model_xgb, testData)
(MSE_test <- mean((secret_data$int_rate-predicted_xgb)^2)) 
```


